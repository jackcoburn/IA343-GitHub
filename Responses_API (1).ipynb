{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_6914bfd30bc081918bd2ad146efc3f58\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-MyhU7DkWiAcZMfvSFXmJ4k\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text (1).json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-MyhU7DkWiAcZMfvSFXmJ4k\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e96e622-9b8c-47d5-9a4a-3c3e6315b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of the latest updates, here are some significant developments in generative AI:\n",
       "\n",
       "1. **Advancements in Multimodal Models**: Models like OpenAI's GPT-4 and Google's Gemini are designed to handle both text and images, enhancing their ability to generate more sophisticated and contextually relevant outputs.\n",
       "\n",
       "2. **Improved Text-to-Image Generation**: Tools like DALL-E 3 and Midjourney have further refined their algorithms to produce more photorealistic and creative images from text prompts.\n",
       "\n",
       "3. **AI in Content Creation**: There's increasing adoption of generative AI in fields like art, music, and video game design, enabling creators to produce complex works with less manual effort.\n",
       "\n",
       "4. **Ethical and Regulatory Focus**: With growing concerns over plagiarism, misinformation, and AI ethics, organizations and governments are working on guidelines to ensure responsible use of generative AI technologies.\n",
       "\n",
       "5. **AI-Driven Personalization**: Companies are leveraging generative models to create personalized marketing content, enhancing customer engagement and targeting.\n",
       "\n",
       "6. **Expanding Applications in Healthcare**: AI is being used to generate synthetic data to train models for medical diagnostics and drug discovery, accelerating research while protecting patient privacy.\n",
       "\n",
       "These advancements reflect the rapid progress and expanding capabilities of generative AI across various sectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in generative AI include:\n",
       "\n",
       "1. **OpenAI's Sora2**: This tool allows users to create cinematic videos from a prompt, incorporating audio, physics, and cameos, offering endless creative possibilities.\n",
       "\n",
       "2. **GPT-5 and DALL¬∑E 4**: These are being used to create unique multimedia experiences, such as combining quantum fractals with music to produce innovative content.\n",
       "\n",
       "3. **Generative AI in Business**: AI is being applied across various sectors, from content generation to design systems, reshaping how businesses innovate.\n",
       "\n",
       "4. **AI in Creative Industries**: Generative AI is transforming creative fields by enabling the production of content like cinematic food commercials without traditional setups.\n",
       "\n",
       "5. **Enterprise Applications**: IBM's Watsonx is bringing generative AI to enterprises, allowing for the creation of custom large language models to enhance customer engagement and streamline processes.\n",
       "\n",
       "These developments highlight the expanding role of generative AI in both creative and business applications, driving innovation and efficiency across industries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a detailed, up-to-date analysis of the **latest developments in Generative AI** as of Wednesday, **November 12, 2025**:\n",
       "\n",
       "---\n",
       "\n",
       "##  Recent Real-World Deployments and Infrastructure Expansion\n",
       "\n",
       "‚Äì **AWS Skill Builder Launches AI-Powered Training Tools**  \n",
       "On November‚ÄØ12, 2025, AWS introduced new components‚Äî**Meeting Simulator**, **Cohorts Studio**, and **microcredentials**‚Äîwithin its Skill Builder platform. These additions enable AI-enhanced communication skills training and group-based learning, and the beta exam for a professional generative AI certification will open for registrations on **November‚ÄØ18** ([aboutamazon.com](https://www.aboutamazon.com/news/aws/aws-ai-certification-learning-tools-skills-development?utm_source=openai)).\n",
       "\n",
       "‚Äì **UT Austin Doubles Generative AI GPU Capacity**  \n",
       "As of today, the University of Texas at Austin has **expanded its AI infrastructure**, more than doubling its training capabilities by increasing GPU resources to over 1,000 units. This expansion significantly bolsters its capacity for generative AI research at academic scale ([quantumzeitgeist.com](https://quantumzeitgeist.com/ut-ai-computing/?utm_source=openai)).\n",
       "\n",
       "‚Äì **Cerebras Systems Launches ‚ÄúCerebras for Nations‚Äù**  \n",
       "On November‚ÄØ11, 2025, Cerebras unveiled **‚ÄúCerebras for Nations‚Äù**, a global program designed to assist governments in building sovereign AI infrastructure. This empowers countries to develop and scale generative AI systems domestically ([hpcwire.com](https://www.hpcwire.com/aiwire/2025/11/11/cerebras-systems-launches-cerebras-for-nations-to-accelerate-and-scale-sovereign-ai/?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Academic Research and Thought Leadership\n",
       "\n",
       "‚Äì **Georgia Tech Cloud Hub Boosts GenAI Research via Microsoft Support**  \n",
       "Today, the Georgia Tech Institute for Data Engineering and Science (IDEaS) concluded a call for proposals for its ‚ÄúCloud Hub‚Äù initiative, funded by Microsoft. This targets foundational and applied generative AI research, fostering innovation across the field ([newswise.com](https://www.newswise.com/articles/georgia-tech-cloud-hub-advances-generative-ai-research-with-microsoft-support?utm_source=openai)).\n",
       "\n",
       "‚Äì **Manchester Study Highlights AI in Teacher Training**  \n",
       "Research from the Manchester Institute of Education reveals early evidence on responsibly embedding generative AI into primary teacher training. The study uses a tool called **TeachMateAI (TMAI)** in the PGCE program, with results from the first year of a three-year longitudinal project ([phys.org](https://phys.org/news/2025-11-ai-teacher.html?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Expanded Use Cases & Ethical Considerations\n",
       "\n",
       "‚Äì **Generative AI Adoption and Labor Market Implications**  \n",
       "A new analysis indicates GenAI is being adopted more broadly and faster than prior digital technologies, offering notable productivity gains in professional tasks (e.g., writing and coding). However, usage remains skewed toward younger, more educated individuals, raising concerns over equitable distribution of benefits ([voxeu.org](https://voxeu.org/voxeu/columns/generative-ai-uneven-adoption-labour-market-returns-and-policy-implications?utm_source=openai)).\n",
       "\n",
       "‚Äì **AI in Scientific Discovery Accelerating Breakthroughs**  \n",
       "In industries from drug discovery to climate modeling, AI systems are now acting not just as tools but as architects of research, accelerating processes that once spanned decades to mere hours or minutes ([webpronews.com](https://www.webpronews.com/ais-quantum-leap-reshaping-science-from-labs-to-breakthroughs/?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Generative AI Tools & Capabilities Advancements\n",
       "\n",
       "‚Äì **Google‚Äôs Pixel Drop AI Enhances On-Device Generative Features**  \n",
       "Google‚Äôs November ‚ÄúPixel Drop AI‚Äù includes real-time generative photo editing in messaging apps, AI-powered content summaries, and improved scam detection features‚Äîall running on-device ([startuphub.ai](https://www.startuphub.ai/ai-news/ai-research/2025/pixel-drop-ai-google-deepens-on-device-intelligence/?amp=1&utm_source=openai)).\n",
       "\n",
       "‚Äì **Agentic Coding: Google Jules Performance**  \n",
       "A newly reported development in AI: **Google‚Äôs Jules**, a coding assistant, performs better than Gemini CLI (though built on the same underlying model), and is competitive with Anthropic‚Äôs Claude Code and OpenAI‚Äôs Codex. Users are still advised to critically verify outputs, recognizing these agentic tools can produce inaccurate or invented information ([infoworld.com](https://www.infoworld.com/article/4086269/agentic-coding-with-google-jules.html?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Contextual Perspective: Recent Model and Technical Breakthroughs\n",
       "\n",
       "- **OpenAI GPT‚Äë5 (Released August 7, 2025)**  \n",
       "  GPT‚Äë5 is a multimodal LLM offering unified reasoning and fast-processing capabilities via internal routing between two primary model types (‚Äúmain‚Äù and ‚Äúthinking‚Äù), with variants like mini and nano optimized for speed or reasoning effort. It's available through ChatGPT, Microsoft Copilot, and the OpenAI API ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai)).\n",
       "\n",
       "- **OpenAI o4‚Äëmini (Released April 16, 2025)**  \n",
       "  A lighter reasoning-capable model capable of processing both text and images, accessible via ChatGPT and API‚Äîincluding a ‚Äúhigh‚Äù variant for enhanced accuracy. It improves tasks such as chemistry-related reasoning but still trails advanced models like DeepSeek‚ÄëR1 ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai)).\n",
       "\n",
       "- **Runway Gen‚Äë4 (Released March 31, 2025)**  \n",
       "  A text-to-video model generating up to 10-second clips with improved character consistency, motion realism, and camera movement. Targeted at previsualization and concept development, it remains limited by clip length and frame rate constraints ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gen-4_%28AI_image_and_video_model%29?utm_source=openai)).\n",
       "\n",
       "- **Google‚Äôs ‚ÄúNano Banana‚Äù (Gemini 2.5 Flash Image, August 2025)**  \n",
       "  A viral text-to-image tool featuring features like multi-image fusion, subject consistency, and SynthID watermarking. It rapidly attracted over 10 million new Gemini app users and produced hundreds of millions of edits ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Synthesis & Outlook\n",
       "\n",
       "The **latest developments in generative AI (as of November 12, 2025)** are characterized by:\n",
       "\n",
       "‚Äì **Broader institutional and governmental deployment**, from AWS‚Äôs AI-based learning platforms to national-level AI infrastructure programs like Cerebras for Nations.  \n",
       "‚Äì **Academic integration and research acceleration**, with universities building capacity and launching long-term AI-enhanced education studies.  \n",
       "‚Äì **Diversification of AI use cases**, spanning teaching, scientific research, and infrastructure. Efficiency gains are notable, yet the equitable reach of these gains remains uneven.  \n",
       "‚Äì **Advances in generative tools**, with strong progress in on-device capabilities, agentic coding, and video/image generation through models like GPT-5, Runway Gen‚Äë4, and Nano Banana.\n",
       "\n",
       "All these point toward a transformative moment where generative AI is becoming deeply embedded across society‚Äîfrom education and government to creative industries‚Äîwhile ethical and access-related considerations remain central.\n",
       "\n",
       "If you'd like deeper insights into any specific area (e.g., a particular tool, policy implications, or academic research), let me know‚ÄîI‚Äôd be happy to explore further.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a detailed, up-to-date analysis of the **latest developments in Generative AI** as of Wednesd"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eedf50-48f8-4092-bb20-c150f3848671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector store\n",
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print('vector store id: ', vector_store_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043556c-bbea-43a4-a4c5-66eaf57673ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload files to file search\n",
    "with open('MLB_pitch_tracking.txt', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485a9d0-9437-4f9c-b4ad-9f6f1328c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach file to vector source\n",
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984ee9f-3da8-4709-a99b-c1d2a12da9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"recent technical and usage developments of mlb pitch tracking system\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330dfe5-7d43-49a9-bdab-02e997020fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11df0c1-abaf-4960-bc55-b0fdd228b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Using my uploaded notes and the latest web information, summarize the current trends on the mlb pitch tracking system.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined search\n",
    "combined_search_response = client.responses.create(\n",
    "    input=query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [vector_store_id],\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c4dd6-4630-4eb7-95c1-3ed35c9e011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
